{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e8be1ad",
   "metadata": {},
   "source": [
    "## CAKE experiment on HX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe1f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from dataset import Dataset\n",
    "from myModel import MyModel, MyDataset\n",
    "from myExplainers import MyExplainer\n",
    "from myEvaluation import MyEvaluation\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import csv\n",
    "import warnings\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from helper import print_results, print_results_ap\n",
    "from cake import CAKE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fee1501",
   "metadata": {},
   "source": [
    "Load model, data and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83e8d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''\n",
    "model_path = 'Trained Models/'\n",
    "save_path = '/home/myloniko/ethos/Results/HX/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23a554c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert'\n",
    "existing_rationales = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa982f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'single_label'\n",
    "labels = 2\n",
    "model = MyModel(model_path, 'bert_hx', model_name, task, labels, False, attention = False)\n",
    "max_sequence_len = model.tokenizer.max_len_single_sentence\n",
    "tokenizer = model.tokenizer\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "model.trainer.model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36163f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hx = Dataset(path = data_path)\n",
    "x, y, label_names, rationales = hx.load_hatexplain(tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "510f54e6",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3edfb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(y))\n",
    "train_texts, test_texts, train_labels, test_labels, _, test_indexes = train_test_split(x, y,  indices, stratify=y, test_size=.2, random_state=42)\n",
    "if existing_rationales:\n",
    "    test_rationales = [rationales[x] for x in test_indexes]\n",
    "\n",
    "size = (0.1 * len(y)) / len(train_labels)\n",
    "train_texts, validation_texts, train_labels, validation_labels = train_test_split(list(train_texts), train_labels, stratify=train_labels, test_size=size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "410b90d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test_rationales = []\n",
    "for test_rational in test_rationales:\n",
    "    test_test_rationales.append([0,test_rational])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab058fec",
   "metadata": {},
   "source": [
    "Define the label descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373ef258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no hate speech', 'hate speech']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names[0] = 'no hate speech'\n",
    "label_names[1] = 'hate speech'\n",
    "description = ['no hate speech label: indicates that the text is considered a normal post and does not contain any instances of hate speech.',\n",
    "            'hate speech label: refers to any text that contains hate speech content, targeting a particular community or individual based on their race, gender, religion, sexual orientation, or other characteristics. These texts may express prejudice, hostility, or aggression towards a particular group or individual, and are intended to cause harm, violence or provoke a negative response.']\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e31bf31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82bcd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for test_text in test_texts:\n",
    "    outputs = model.my_predict(test_text)\n",
    "    predictions.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f521280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8125636883823175 0.8829090909090909 0.8796580031301151 0.8598781549173194\n"
     ]
    }
   ],
   "source": [
    "pred_labels = []\n",
    "for prediction in predictions:\n",
    "    pred_labels.append(np.argmax(softmax(prediction[0])))\n",
    "\n",
    "def average_precision_wrapper(y, y_pred, view):\n",
    "    return average_precision_score(y, y_pred.toarray(), average=view)\n",
    "\n",
    "print(average_precision_score(test_labels, pred_labels, average='macro'), accuracy_score(test_labels, pred_labels), f1_score(test_labels, pred_labels, average='macro'), f1_score(test_labels, pred_labels, average='binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1805fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_arrays = []\n",
    "for i in range(0,len(train_labels)):\n",
    "    train_label_arrays.append([train_labels[i],abs(1-train_labels[i])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9ea6447",
   "metadata": {},
   "source": [
    "Create a small cake (CAKE's instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "11693903",
   "metadata": {},
   "outputs": [],
   "source": [
    "cake = CAKE(model_path = 'Trained Models/bert_hx', tokenizer = tokenizer, label_names = label_names, \n",
    "            label_descriptions = description, input_docs = train_texts, input_labels = train_label_arrays, \n",
    "            input_docs_test = test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08f9a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_explainers = MyExplainer(label_names, model, cake = cake)\n",
    "\n",
    "my_evaluators = MyEvaluation(label_names, model.my_predict, False, True)\n",
    "my_evaluatorsP = MyEvaluation(label_names, model.my_predict, False, False)\n",
    "evaluation =  {'F':my_evaluators.faithfulness, 'FTP': my_evaluators.faithful_truthfulness_penalty, \n",
    "          'NZW': my_evaluators.nzw, 'AUPRC': my_evaluators.auprc}\n",
    "evaluationP = {'F':my_evaluatorsP.faithfulness, 'FTP': my_evaluatorsP.faithful_truthfulness_penalty, \n",
    "          'NZW': my_evaluatorsP.nzw, 'AUPRC': my_evaluators.auprc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c76ea825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs = []\n",
    "for key_emb in [1, 2, 3]:\n",
    "    for label_emb in [1, 2, \"2_doc\", 3]:\n",
    "        for keyphrases in [5, 10, 15, 20]: \n",
    "            for width in [0, 1, 3, 5]:\n",
    "                for negatives in [False]:\n",
    "                    confs.append([key_emb, label_emb, keyphrases, width, negatives])\n",
    "len(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b428d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    file_name = save_path + 'HX_BERT_CAKEZ_NEW15_'+str(now.day) + '_' + str(now.month) + '_' + str(now.year)\n",
    "    metrics = {'F':[], 'FTP':[], 'AUPRC': [], 'NZW':[]}\n",
    "    metricsP = {'F':[], 'FTP':[], 'AUPRC': [], 'NZW':[]}\n",
    "    time_r = []\n",
    "    for conf in confs:\n",
    "        time_r.append([])\n",
    "    techniques = [my_explainers.cake_explain] \n",
    "    for ind in tqdm(range(0,len(test_texts))):\n",
    "        torch.cuda.empty_cache() \n",
    "        test_rational = test_test_rationales[ind]\n",
    "        instance = test_texts[ind]\n",
    "        my_evaluators.clear_states()\n",
    "        my_evaluatorsP.clear_states()\n",
    "        prediction, _, _ = model.my_predict(instance)\n",
    "        enc = model.tokenizer([instance,instance], truncation=True, padding=True)[0]\n",
    "        mask = enc.attention_mask\n",
    "        tokens = enc.tokens\n",
    "    \n",
    "        interpretations = []\n",
    "        kk = 0\n",
    "        for conf in confs:\n",
    "            ts = time.time()\n",
    "            if conf[1] == 3:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], ind, conf[2], conf[3], conf[4]]\n",
    "            else:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], None, conf[2], conf[3], conf[4]]\n",
    "            temp = techniques[0](instance, prediction, tokens, mask, _, _)\n",
    "            interpretations.append([np.array(i)/np.max(np.abs(i)) if np.max(np.abs(i))!=0 else np.zeros(len(i)) for i in temp])\n",
    "            time_r[kk].append(time.time()-ts)\n",
    "            kk = kk + 1\n",
    "        for metric in metrics.keys():\n",
    "            evaluated = []\n",
    "            for interpretation in interpretations:\n",
    "                evaluated.append(evaluation[metric](interpretation, _, instance, prediction, tokens, _, _, test_rational))\n",
    "            metrics[metric].append(evaluated)\n",
    "        my_evaluatorsP.saved_state = my_evaluators.saved_state.copy()\n",
    "        my_evaluators.clear_states()\n",
    "        for metric in metrics.keys():\n",
    "            evaluatedP = []\n",
    "            for interpretation in interpretations:\n",
    "                evaluatedP.append(evaluationP[metric](interpretation, _, instance, prediction, tokens, _, _, test_rational))\n",
    "            metricsP[metric].append(evaluatedP)\n",
    "        with open(file_name+'(A).pickle', 'wb') as handle:\n",
    "            pickle.dump(metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(file_name+'(P).pickle', 'wb') as handle:\n",
    "            pickle.dump(metricsP, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(file_name+'_TIME.pickle', 'wb') as handle:\n",
    "            pickle.dump(time_r, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "time_r = np.array(time_r)\n",
    "time_r.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1230184",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(file_name+'(P)', confs, metricsP, label_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e6a4cc8",
   "metadata": {},
   "source": [
    "# Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87c75b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs = []\n",
    "for key_emb in [1, 2, 3]:\n",
    "    for label_emb in [1, 2, 3]:\n",
    "        for keyphrases in [5, 10, 15, 20]:\n",
    "            for width in [0, 1, 2, 3]:\n",
    "                for negatives in [False]:\n",
    "                    confs.append([key_emb, label_emb, keyphrases, width, negatives])\n",
    "len(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    time_r = []\n",
    "    for conf in confs:\n",
    "        time_r.append([])\n",
    "    techniques = [my_explainers.cake_explain] \n",
    "    for ind in tqdm(range(10),position=0):\n",
    "        torch.cuda.empty_cache() \n",
    "        test_rational = test_test_rationales[ind]\n",
    "        instance = test_texts[ind]\n",
    "        my_evaluators.clear_states()\n",
    "        my_evaluatorsP.clear_states()\n",
    "        prediction, _, _ = model.my_predict(instance)\n",
    "        enc = model.tokenizer([instance,instance], truncation=True, padding=True)[0]\n",
    "        mask = enc.attention_mask\n",
    "        tokens = enc.tokens\n",
    "    \n",
    "        interpretations = []\n",
    "        kk = 0\n",
    "        for conf in tqdm(confs,position=1):\n",
    "            ts = time.time()\n",
    "            if conf[1] == 3:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], ind, conf[2], conf[3], conf[4]]\n",
    "            else:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], None, conf[2], conf[3], conf[4]]\n",
    "            temp = techniques[0](instance, prediction, tokens, mask, _, _)\n",
    "            aa = [np.array(i)/np.max(np.abs(i)) if np.max(np.abs(i))!=0 else np.zeros(len(i)) for i in temp]\n",
    "            time_r[kk].append(time.time()-ts)\n",
    "            kk = kk + 1\n",
    "time_r = np.array(time_r)\n",
    "time_r.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bf0267c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 1, 5, 0, False], 0.20240824222564696),\n",
       " ([1, 1, 5, 1, False], 0.18215610980987548),\n",
       " ([1, 1, 5, 2, False], 0.17879729270935057),\n",
       " ([1, 1, 5, 3, False], 0.17538561820983886),\n",
       " ([1, 1, 10, 0, False], 0.1756798267364502),\n",
       " ([1, 1, 10, 1, False], 0.17891762256622315),\n",
       " ([1, 1, 10, 2, False], 0.17377197742462158),\n",
       " ([1, 1, 10, 3, False], 0.1742172956466675),\n",
       " ([1, 1, 15, 0, False], 0.18079848289489747),\n",
       " ([1, 1, 15, 1, False], 0.17449276447296141),\n",
       " ([1, 1, 15, 2, False], 0.18197460174560548),\n",
       " ([1, 1, 15, 3, False], 0.17809457778930665),\n",
       " ([1, 1, 20, 0, False], 0.18089168071746825),\n",
       " ([1, 1, 20, 1, False], 0.1812676191329956),\n",
       " ([1, 1, 20, 2, False], 0.17982659339904786),\n",
       " ([1, 1, 20, 3, False], 0.17641468048095704),\n",
       " ([1, 2, 5, 0, False], 0.17588987350463867),\n",
       " ([1, 2, 5, 1, False], 0.17306714057922362),\n",
       " ([1, 2, 5, 2, False], 0.17635812759399414),\n",
       " ([1, 2, 5, 3, False], 0.17486019134521485),\n",
       " ([1, 2, 10, 0, False], 0.17772600650787354),\n",
       " ([1, 2, 10, 1, False], 0.17597620487213134),\n",
       " ([1, 2, 10, 2, False], 0.1739133358001709),\n",
       " ([1, 2, 10, 3, False], 0.17300713062286377),\n",
       " ([1, 2, 15, 0, False], 0.17774624824523927),\n",
       " ([1, 2, 15, 1, False], 0.1778806447982788),\n",
       " ([1, 2, 15, 2, False], 0.17641012668609618),\n",
       " ([1, 2, 15, 3, False], 0.174684476852417),\n",
       " ([1, 2, 20, 0, False], 0.17376446723937988),\n",
       " ([1, 2, 20, 1, False], 0.17499928474426268),\n",
       " ([1, 2, 20, 2, False], 0.17750766277313232),\n",
       " ([1, 2, 20, 3, False], 0.17833409309387208),\n",
       " ([1, 3, 5, 0, False], 0.1719031572341919),\n",
       " ([1, 3, 5, 1, False], 0.17366256713867187),\n",
       " ([1, 3, 5, 2, False], 0.17771623134613038),\n",
       " ([1, 3, 5, 3, False], 0.17800276279449462),\n",
       " ([1, 3, 10, 0, False], 0.17373335361480713),\n",
       " ([1, 3, 10, 1, False], 0.17598414421081543),\n",
       " ([1, 3, 10, 2, False], 0.17255947589874268),\n",
       " ([1, 3, 10, 3, False], 0.18085436820983886),\n",
       " ([1, 3, 15, 0, False], 0.17822115421295165),\n",
       " ([1, 3, 15, 1, False], 0.17163405418395997),\n",
       " ([1, 3, 15, 2, False], 0.17458806037902833),\n",
       " ([1, 3, 15, 3, False], 0.17370827198028566),\n",
       " ([1, 3, 20, 0, False], 0.17530441284179688),\n",
       " ([1, 3, 20, 1, False], 0.1753618001937866),\n",
       " ([1, 3, 20, 2, False], 0.18220350742340088),\n",
       " ([1, 3, 20, 3, False], 0.17724347114562988),\n",
       " ([2, 1, 5, 0, False], 0.8933237552642822),\n",
       " ([2, 1, 5, 1, False], 0.8384324550628662),\n",
       " ([2, 1, 5, 2, False], 0.8717461585998535),\n",
       " ([2, 1, 5, 3, False], 0.895902419090271),\n",
       " ([2, 1, 10, 0, False], 0.8941371440887451),\n",
       " ([2, 1, 10, 1, False], 0.9047940969467163),\n",
       " ([2, 1, 10, 2, False], 0.9212092638015748),\n",
       " ([2, 1, 10, 3, False], 0.8686349630355835),\n",
       " ([2, 1, 15, 0, False], 0.8767217636108399),\n",
       " ([2, 1, 15, 1, False], 0.8922633647918701),\n",
       " ([2, 1, 15, 2, False], 0.9236237287521363),\n",
       " ([2, 1, 15, 3, False], 0.9018921375274658),\n",
       " ([2, 1, 20, 0, False], 0.8865476131439209),\n",
       " ([2, 1, 20, 1, False], 0.9374596357345581),\n",
       " ([2, 1, 20, 2, False], 0.9207848310470581),\n",
       " ([2, 1, 20, 3, False], 0.8868056058883667),\n",
       " ([2, 2, 5, 0, False], 0.8986085891723633),\n",
       " ([2, 2, 5, 1, False], 0.8707071304321289),\n",
       " ([2, 2, 5, 2, False], 0.8950988054275513),\n",
       " ([2, 2, 5, 3, False], 0.933634352684021),\n",
       " ([2, 2, 10, 0, False], 0.8933324337005615),\n",
       " ([2, 2, 10, 1, False], 0.9002521991729736),\n",
       " ([2, 2, 10, 2, False], 0.8959094285964966),\n",
       " ([2, 2, 10, 3, False], 0.9061588764190673),\n",
       " ([2, 2, 15, 0, False], 0.8685431480407715),\n",
       " ([2, 2, 15, 1, False], 0.8853370904922485),\n",
       " ([2, 2, 15, 2, False], 0.9443609237670898),\n",
       " ([2, 2, 15, 3, False], 0.9385086536407471),\n",
       " ([2, 2, 20, 0, False], 0.8766855716705322),\n",
       " ([2, 2, 20, 1, False], 0.892312741279602),\n",
       " ([2, 2, 20, 2, False], 0.9075688600540162),\n",
       " ([2, 2, 20, 3, False], 0.8753649950027466),\n",
       " ([2, 3, 5, 0, False], 0.8925611495971679),\n",
       " ([2, 3, 5, 1, False], 0.9170114278793335),\n",
       " ([2, 3, 5, 2, False], 0.89671471118927),\n",
       " ([2, 3, 5, 3, False], 0.9100401639938355),\n",
       " ([2, 3, 10, 0, False], 0.9459726572036743),\n",
       " ([2, 3, 10, 1, False], 0.8950148344039917),\n",
       " ([2, 3, 10, 2, False], 0.8837616443634033),\n",
       " ([2, 3, 10, 3, False], 0.8958774328231811),\n",
       " ([2, 3, 15, 0, False], 0.9513233423233032),\n",
       " ([2, 3, 15, 1, False], 0.914638090133667),\n",
       " ([2, 3, 15, 2, False], 0.8725513458251953),\n",
       " ([2, 3, 15, 3, False], 0.8788052082061768),\n",
       " ([2, 3, 20, 0, False], 0.9419906616210938),\n",
       " ([2, 3, 20, 1, False], 0.8931892156600952),\n",
       " ([2, 3, 20, 2, False], 0.8719474077224731),\n",
       " ([2, 3, 20, 3, False], 0.8830526351928711),\n",
       " ([3, 1, 5, 0, False], 0.2502191781997681),\n",
       " ([3, 1, 5, 1, False], 0.24807941913604736),\n",
       " ([3, 1, 5, 2, False], 0.26323068141937256),\n",
       " ([3, 1, 5, 3, False], 0.25250420570373533),\n",
       " ([3, 1, 10, 0, False], 0.2528035879135132),\n",
       " ([3, 1, 10, 1, False], 0.24580178260803223),\n",
       " ([3, 1, 10, 2, False], 0.2520500898361206),\n",
       " ([3, 1, 10, 3, False], 0.2460498809814453),\n",
       " ([3, 1, 15, 0, False], 0.2481558084487915),\n",
       " ([3, 1, 15, 1, False], 0.24369392395019532),\n",
       " ([3, 1, 15, 2, False], 0.2493204116821289),\n",
       " ([3, 1, 15, 3, False], 0.2429969310760498),\n",
       " ([3, 1, 20, 0, False], 0.2514843225479126),\n",
       " ([3, 1, 20, 1, False], 0.24950361251831055),\n",
       " ([3, 1, 20, 2, False], 0.2550123929977417),\n",
       " ([3, 1, 20, 3, False], 0.2523754835128784),\n",
       " ([3, 2, 5, 0, False], 0.24773528575897216),\n",
       " ([3, 2, 5, 1, False], 0.24563047885894776),\n",
       " ([3, 2, 5, 2, False], 0.247194504737854),\n",
       " ([3, 2, 5, 3, False], 0.24175186157226564),\n",
       " ([3, 2, 10, 0, False], 0.24799189567565919),\n",
       " ([3, 2, 10, 1, False], 0.24466333389282227),\n",
       " ([3, 2, 10, 2, False], 0.2502591609954834),\n",
       " ([3, 2, 10, 3, False], 0.244688081741333),\n",
       " ([3, 2, 15, 0, False], 0.24302756786346436),\n",
       " ([3, 2, 15, 1, False], 0.2445244312286377),\n",
       " ([3, 2, 15, 2, False], 0.2622356414794922),\n",
       " ([3, 2, 15, 3, False], 0.24670493602752686),\n",
       " ([3, 2, 20, 0, False], 0.2491990089416504),\n",
       " ([3, 2, 20, 1, False], 0.24423317909240722),\n",
       " ([3, 2, 20, 2, False], 0.24806632995605468),\n",
       " ([3, 2, 20, 3, False], 0.25035388469696046),\n",
       " ([3, 3, 5, 0, False], 0.2408689498901367),\n",
       " ([3, 3, 5, 1, False], 0.24458320140838624),\n",
       " ([3, 3, 5, 2, False], 0.25191869735717776),\n",
       " ([3, 3, 5, 3, False], 0.25089077949523925),\n",
       " ([3, 3, 10, 0, False], 0.24768335819244386),\n",
       " ([3, 3, 10, 1, False], 0.2508692264556885),\n",
       " ([3, 3, 10, 2, False], 0.25183298587799074),\n",
       " ([3, 3, 10, 3, False], 0.2435368776321411),\n",
       " ([3, 3, 15, 0, False], 0.2518209934234619),\n",
       " ([3, 3, 15, 1, False], 0.2459869861602783),\n",
       " ([3, 3, 15, 2, False], 0.2444835424423218),\n",
       " ([3, 3, 15, 3, False], 0.25068249702453616),\n",
       " ([3, 3, 20, 0, False], 0.24625890254974364),\n",
       " ([3, 3, 20, 1, False], 0.241552734375),\n",
       " ([3, 3, 20, 2, False], 0.23909516334533693),\n",
       " ([3, 3, 20, 3, False], 0.24121496677398682)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(confs,list(time_r.mean(axis=1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
