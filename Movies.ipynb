{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c2d59ae",
   "metadata": {},
   "source": [
    "## CAKE experiment on Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3148557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
    "from dataset import Dataset\n",
    "from myModel import MyModel, MyDataset\n",
    "from myExplainers import MyExplainer\n",
    "from myEvaluation import MyEvaluation\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import csv\n",
    "import warnings\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from scipy.special import softmax\n",
    "from helper import print_results\n",
    "from cake import CAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c7fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "195c2f87",
   "metadata": {},
   "source": [
    "Load model, data, and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc1140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''\n",
    "model_path = 'Trained Models/'\n",
    "save_path = '/home/myloniko/ethos/Results/MV/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73542b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert'\n",
    "existing_rationales = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daed578",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'single_label'\n",
    "sentence_level = True\n",
    "labels = 2\n",
    "model = MyModel(model_path, 'bert_movies', model_name, task, labels, False)\n",
    "max_sequence_len = model.tokenizer.max_len_single_sentence\n",
    "tokenizer = model.tokenizer\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "model.trainer.model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c51b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myloniko/ethos/dataset.py:77: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.rationales = np.array(rationales)\n"
     ]
    }
   ],
   "source": [
    "mv = Dataset(path = data_path)\n",
    "x, y, label_names, rationales = mv.load_movies(level='sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f37abb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "existing_rationales = True\n",
    "indices = np.arange(len(y))\n",
    "train_texts, test_texts, train_labels, test_labels, _, test_indexes = train_test_split(x, list(y), indices, test_size=.2, random_state=42)\n",
    "if existing_rationales:\n",
    "    test_rationales = [rationales[x] for x in test_indexes]\n",
    "size = (0.1 * len(y)) / len(train_labels)\n",
    "train_texts, validation_texts, train_labels, validation_labels = train_test_split(list(train_texts), train_labels, test_size=size, random_state=42)\n",
    "train_texts.append(test_texts[84])\n",
    "train_labels.append(test_labels[84])\n",
    "train_texts.append(test_texts[72])\n",
    "train_labels.append(test_labels[72])\n",
    "test_texts.pop(84)\n",
    "test_labels.pop(84)\n",
    "test_rationales.pop(84)\n",
    "test_texts.pop(72)\n",
    "test_labels.pop(72)\n",
    "test_rationales.pop(72)\n",
    "test_texts.pop(63)\n",
    "test_labels.pop(63)\n",
    "test_rationales.pop(63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "172c5f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test_rationales = []\n",
    "for i in range(len(test_rationales)):\n",
    "    if (test_labels[i] == 1):\n",
    "        test_test_rationales.append([[0]*len(test_rationales[i][:-1]),list(test_rationales[i][:-1])])\n",
    "    else:\n",
    "        test_test_rationales.append([list(test_rationales[i][:-1]),[0]* len(test_rationales[i][:-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2c575",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for test_text in test_texts:\n",
    "    outputs = model.my_predict(test_text)\n",
    "    predictions.append(outputs[0])\n",
    "\n",
    "pred_labels = []\n",
    "for prediction in predictions:\n",
    "    pred_labels.append(np.argmax(softmax(prediction)))\n",
    "\n",
    "def average_precision_wrapper(y, y_pred, view):\n",
    "    return average_precision_score(y, y_pred.toarray(), average=view)\n",
    "\n",
    "average_precision_score(test_labels, pred_labels, average='macro'), accuracy_score(test_labels, pred_labels), f1_score(test_labels, pred_labels, average='macro'), f1_score(test_labels, pred_labels, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7379e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NEG', 'POS']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ece2a3c",
   "metadata": {},
   "source": [
    "Define descriptions for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "830788ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "description=[\"positive: The positive sentiment in the context of the Movies dataset refers to the overall positive tone of a movie review. It indicates that the reviewer has expressed a favorable opinion of the movie they have watched. Examples of positive sentiment in movie reviews include praising the plot, complimenting the acting or directing, or expressing overall satisfaction with the film. Identifying positive sentiment is an important task in natural language processing and sentiment analysis, as it can provide insights into the public perception of a movie and help businesses gauge customer satisfaction.\",\n",
    "        \"negative: The negative sentiment label in the Movies dataset refers to the overall negative tone of a movie review. It indicates that the reviewer has expressed an unfavorable opinion of the movie they have watched. Examples of negative sentiment in movie reviews might include criticism of the plot, acting, or directing, or expressing overall dissatisfaction with the film. Identifying negative sentiment is an important task in sentiment analysis, as it can help businesses understand what aspects of their product or service are not meeting customer expectations, and can provide insights into how they might improve customer satisfaction.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30012c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_arrays=[]\n",
    "for i in range(0,len(train_labels)):\n",
    "    train_label_arrays.append([train_labels[i],abs(1-train_labels[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96bb8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "cake = CAKE(model_path = 'Trained Models/bert_movies', tokenizer = tokenizer, label_names = label_names, \n",
    "            label_descriptions = description, input_docs = train_texts, input_labels = train_label_arrays, \n",
    "            input_docs_test = test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68d18599",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_explainers = MyExplainer(label_names, model, True, 'â€¡', cake=cake)\n",
    "\n",
    "my_evaluators = MyEvaluation(label_names, model.my_predict, True, True)\n",
    "my_evaluatorsP = MyEvaluation(label_names, model.my_predict, True, False)\n",
    "evaluation =  {'F':my_evaluators.faithfulness, 'FTP': my_evaluators.faithful_truthfulness_penalty, \n",
    "          'NZW': my_evaluators.nzw, 'AUPRC': my_evaluators.auprc}\n",
    "evaluationP = {'F':my_evaluatorsP.faithfulness, 'FTP': my_evaluatorsP.faithful_truthfulness_penalty, \n",
    "          'NZW': my_evaluatorsP.nzw, 'AUPRC': my_evaluators.auprc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72135a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs = []\n",
    "for key_emb in [1, 2, 3]:\n",
    "    for label_emb in [1, 2, \"2_doc\", 3]:\n",
    "        for keyphrases in [5, 10, 15, 20]:\n",
    "            for width in [0, 1, 2, 3]:\n",
    "                for negatives in [True, False]:\n",
    "                    confs.append([key_emb, label_emb, keyphrases, width, negatives])\n",
    "len(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd68c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    file_name = save_path + 'MOVIES_BERT_SENTENCE_CAKE_1_2_1_'+str(now.day) + '_' + str(now.month) + '_' + str(now.year)\n",
    "    metrics = {'F':[], 'FTP':[], 'NZW':[], 'AUPRC':[]}\n",
    "    metricsP = {'F':[], 'FTP':[], 'NZW':[], 'AUPRC':[]}\n",
    "    time_r = []\n",
    "    for conf in confs:\n",
    "        time_r.append([])\n",
    "    techniques = [my_explainers.cake_explain] \n",
    "    for ind in tqdm(range(0,len(test_texts))):\n",
    "        torch.cuda.empty_cache() \n",
    "        test_rational = test_test_rationales[ind]\n",
    "        instance = test_texts[ind]\n",
    "        my_evaluators.clear_states()\n",
    "        my_evaluatorsP.clear_states()\n",
    "        prediction, _, _ = model.my_predict(instance)\n",
    "        enc = model.tokenizer([instance,instance], truncation=True, padding=True)[0]\n",
    "        mask = enc.attention_mask\n",
    "        tokens = enc.tokens\n",
    "    \n",
    "        interpretations = []\n",
    "        kk = 0\n",
    "        for conf in confs:\n",
    "            if conf[1] == 3:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], ind, conf[2], conf[3], conf[4]]\n",
    "            else:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], None, conf[2], conf[3], conf[4]]\n",
    "            ts = time.time()\n",
    "            temp = techniques[0](instance, prediction, tokens, mask, _, _)\n",
    "            temp_tokens = tokens.copy()\n",
    "            if sentence_level:\n",
    "                temp_tokens = temp[0].copy()[0]\n",
    "                temp = temp[1].copy()\n",
    "            interpretations.append([np.array(i)/np.max(np.abs(i)) if np.max(np.abs(i))!=0 else np.zeros(len(i)) for i in temp])\n",
    "            time_r[kk].append(time.time()-ts)\n",
    "            kk = kk + 1\n",
    "        for metric in metrics.keys():\n",
    "            evaluated = []\n",
    "            for interpretation in interpretations:\n",
    "                evaluated.append(evaluation[metric](interpretation, _, instance, prediction, temp_tokens, _, _, test_rational))\n",
    "            metrics[metric].append(evaluated)\n",
    "        my_evaluatorsP.saved_state = my_evaluators.saved_state.copy()\n",
    "        my_evaluators.clear_states()\n",
    "        for metric in metrics.keys():\n",
    "            evaluatedP = []\n",
    "            for interpretation in interpretations:\n",
    "                evaluatedP.append(evaluationP[metric](interpretation, _, instance, prediction, temp_tokens, _, _, test_rational))\n",
    "            metricsP[metric].append(evaluatedP)\n",
    "        with open(file_name+'(A).pickle', 'wb') as handle:\n",
    "            pickle.dump(metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(file_name+'(P).pickle', 'wb') as handle:\n",
    "            pickle.dump(metricsP, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(file_name+'_TIME.pickle', 'wb') as handle:\n",
    "            pickle.dump(time_r, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "time_r = np.array(time_r)\n",
    "time_r.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(file_name+'(P)', confs, metricsP, label_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "666b33d0",
   "metadata": {},
   "source": [
    "# Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37db5ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs = []\n",
    "for key_emb in [1, 2, 3]:\n",
    "    for label_emb in [1, 2, 3]:\n",
    "        for keyphrases in [5, 10, 15, 20]:\n",
    "            for width in [0, 1, 2, 3]:\n",
    "                for negatives in [False]:\n",
    "                    confs.append([key_emb, label_emb, keyphrases, width, negatives])\n",
    "len(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d57e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    time_r = []\n",
    "    for conf in confs:\n",
    "        time_r.append([])\n",
    "    techniques = [my_explainers.cake_explain] \n",
    "    for ind in tqdm(range(0,10), position=0):\n",
    "        torch.cuda.empty_cache() \n",
    "        test_rational = test_test_rationales[ind]\n",
    "        instance = test_texts[ind]\n",
    "        my_evaluators.clear_states()\n",
    "        my_evaluatorsP.clear_states()\n",
    "        prediction, _, _ = model.my_predict(instance)\n",
    "        enc = model.tokenizer([instance,instance], truncation=True, padding=True)[0]\n",
    "        mask = enc.attention_mask\n",
    "        tokens = enc.tokens\n",
    "    \n",
    "        interpretations = []\n",
    "        kk = 0\n",
    "        for conf in tqdm(confs, position=1, leave=False):\n",
    "            #print(conf)\n",
    "            if conf[1] == 3:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], ind, conf[2], conf[3], conf[4]]\n",
    "            else:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], None, conf[2], conf[3], conf[4]]\n",
    "            ts = time.time()\n",
    "            temp = techniques[0](instance, prediction, tokens, mask, _, _)\n",
    "            temp_tokens = tokens.copy()\n",
    "            if sentence_level:\n",
    "                temp_tokens = temp[0].copy()[0]\n",
    "                temp = temp[1].copy()\n",
    "            aaaa = [np.array(i)/np.max(np.abs(i)) if np.max(np.abs(i))!=0 else np.zeros(len(i)) for i in temp]\n",
    "            time_r[kk].append(time.time()-ts)\n",
    "            kk = kk + 1\n",
    "time_r = np.array(time_r)\n",
    "time_r.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8a1a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_r2 = np.array(nt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97e5fb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 1, 5, 0, False], 0.4223729848861694),\n",
       " ([1, 1, 5, 1, False], 0.4299570322036743),\n",
       " ([1, 1, 5, 2, False], 0.43325784206390383),\n",
       " ([1, 1, 5, 3, False], 0.42571249008178713),\n",
       " ([1, 1, 10, 0, False], 0.43698935508728026),\n",
       " ([1, 1, 10, 1, False], 0.42425272464752195),\n",
       " ([1, 1, 10, 2, False], 0.4416362285614014),\n",
       " ([1, 1, 10, 3, False], 0.427693247795105),\n",
       " ([1, 1, 15, 0, False], 0.4219777822494507),\n",
       " ([1, 1, 15, 1, False], 0.42236201763153075),\n",
       " ([1, 1, 15, 2, False], 0.4425539970397949),\n",
       " ([1, 1, 15, 3, False], 0.4239311933517456),\n",
       " ([1, 1, 20, 0, False], 0.42103238105773927),\n",
       " ([1, 1, 20, 1, False], 0.4258598566055298),\n",
       " ([1, 1, 20, 2, False], 0.42176084518432616),\n",
       " ([1, 1, 20, 3, False], 0.4171828031539917),\n",
       " ([1, 2, 5, 0, False], 0.42262930870056153),\n",
       " ([1, 2, 5, 1, False], 0.41694817543029783),\n",
       " ([1, 2, 5, 2, False], 0.432607626914978),\n",
       " ([1, 2, 5, 3, False], 0.42190544605255126),\n",
       " ([1, 2, 10, 0, False], 0.4257162094116211),\n",
       " ([1, 2, 10, 1, False], 0.42602787017822263),\n",
       " ([1, 2, 10, 2, False], 0.41904456615448),\n",
       " ([1, 2, 10, 3, False], 0.4267608642578125),\n",
       " ([1, 2, 15, 0, False], 0.42632322311401366),\n",
       " ([1, 2, 15, 1, False], 0.4436624050140381),\n",
       " ([1, 2, 15, 2, False], 0.4349552631378174),\n",
       " ([1, 2, 15, 3, False], 0.42426917552947996),\n",
       " ([1, 2, 20, 0, False], 0.42239181995391845),\n",
       " ([1, 2, 20, 1, False], 0.4236454963684082),\n",
       " ([1, 2, 20, 2, False], 0.4282092571258545),\n",
       " ([1, 2, 20, 3, False], 0.42674617767333983),\n",
       " ([1, 3, 5, 0, False], 0.42272019386291504),\n",
       " ([1, 3, 5, 1, False], 0.43216452598571775),\n",
       " ([1, 3, 5, 2, False], 0.41923184394836427),\n",
       " ([1, 3, 5, 3, False], 0.4266349315643311),\n",
       " ([1, 3, 10, 0, False], 0.4236764430999756),\n",
       " ([1, 3, 10, 1, False], 0.4221210479736328),\n",
       " ([1, 3, 10, 2, False], 0.4156105756759644),\n",
       " ([1, 3, 10, 3, False], 0.4230684995651245),\n",
       " ([1, 3, 15, 0, False], 0.4425946235656738),\n",
       " ([1, 3, 15, 1, False], 0.43127193450927737),\n",
       " ([1, 3, 15, 2, False], 0.4260531187057495),\n",
       " ([1, 3, 15, 3, False], 0.42761805057525637),\n",
       " ([1, 3, 20, 0, False], 0.42009403705596926),\n",
       " ([1, 3, 20, 1, False], 0.42653713226318357),\n",
       " ([1, 3, 20, 2, False], 0.42025983333587646),\n",
       " ([1, 3, 20, 3, False], 0.4236778736114502),\n",
       " ([2, 1, 5, 0, False], 0.9753232002258301),\n",
       " ([2, 1, 5, 1, False], 0.9254981279373169),\n",
       " ([2, 1, 5, 2, False], 0.9615968942642212),\n",
       " ([2, 1, 5, 3, False], 1.0335517168045043),\n",
       " ([2, 1, 10, 0, False], 0.9686147689819335),\n",
       " ([2, 1, 10, 1, False], 1.0138010263442994),\n",
       " ([2, 1, 10, 2, False], 1.039413070678711),\n",
       " ([2, 1, 10, 3, False], 0.985838770866394),\n",
       " ([2, 1, 15, 0, False], 1.0076722860336305),\n",
       " ([2, 1, 15, 1, False], 0.9995333433151246),\n",
       " ([2, 1, 15, 2, False], 0.9972459554672242),\n",
       " ([2, 1, 15, 3, False], 0.9591871976852417),\n",
       " ([2, 1, 20, 0, False], 0.979807710647583),\n",
       " ([2, 1, 20, 1, False], 0.9976135969161988),\n",
       " ([2, 1, 20, 2, False], 1.0092512845993042),\n",
       " ([2, 1, 20, 3, False], 0.9988232612609863),\n",
       " ([2, 2, 5, 0, False], 0.9728509902954101),\n",
       " ([2, 2, 5, 1, False], 1.0002496004104615),\n",
       " ([2, 2, 5, 2, False], 1.0506924152374268),\n",
       " ([2, 2, 5, 3, False], 0.9995004653930664),\n",
       " ([2, 2, 10, 0, False], 0.9428427219390869),\n",
       " ([2, 2, 10, 1, False], 1.0470730066299438),\n",
       " ([2, 2, 10, 2, False], 1.0087238788604735),\n",
       " ([2, 2, 10, 3, False], 0.9913449048995971),\n",
       " ([2, 2, 15, 0, False], 1.0315060377120973),\n",
       " ([2, 2, 15, 1, False], 0.982671570777893),\n",
       " ([2, 2, 15, 2, False], 0.9710172414779663),\n",
       " ([2, 2, 15, 3, False], 1.0243979215621948),\n",
       " ([2, 2, 20, 0, False], 0.9938221454620362),\n",
       " ([2, 2, 20, 1, False], 1.0258590221405028),\n",
       " ([2, 2, 20, 2, False], 1.0827070236206056),\n",
       " ([2, 2, 20, 3, False], 0.9900261878967285),\n",
       " ([2, 3, 5, 0, False], 0.9839989900588989),\n",
       " ([2, 3, 5, 1, False], 1.032321524620056),\n",
       " ([2, 3, 5, 2, False], 0.9797820806503296),\n",
       " ([2, 3, 5, 3, False], 0.960602855682373),\n",
       " ([2, 3, 10, 0, False], 1.020524787902832),\n",
       " ([2, 3, 10, 1, False], 0.9887957096099853),\n",
       " ([2, 3, 10, 2, False], 0.9911170482635498),\n",
       " ([2, 3, 10, 3, False], 1.0294741153717042),\n",
       " ([2, 3, 15, 0, False], 1.0029757976531983),\n",
       " ([2, 3, 15, 1, False], 0.9908794164657593),\n",
       " ([2, 3, 15, 2, False], 1.0420200824737549),\n",
       " ([2, 3, 15, 3, False], 1.0317997694015504),\n",
       " ([2, 3, 20, 0, False], 1.0003411531448365),\n",
       " ([2, 3, 20, 1, False], 0.9796894311904907),\n",
       " ([2, 3, 20, 2, False], 0.9920592069625854),\n",
       " ([2, 3, 20, 3, False], 0.9823569059371948),\n",
       " ([3, 1, 5, 0, False], 1.0066931962966919),\n",
       " ([3, 1, 5, 1, False], 0.9381303548812866),\n",
       " ([3, 1, 5, 2, False], 0.9339090347290039),\n",
       " ([3, 1, 5, 3, False], 0.9230018854141235),\n",
       " ([3, 1, 10, 0, False], 0.9511443138122558),\n",
       " ([3, 1, 10, 1, False], 0.9200674057006836),\n",
       " ([3, 1, 10, 2, False], 0.9407789945602417),\n",
       " ([3, 1, 10, 3, False], 0.981669569015503),\n",
       " ([3, 1, 15, 0, False], 0.9271261930465698),\n",
       " ([3, 1, 15, 1, False], 0.9195076704025269),\n",
       " ([3, 1, 15, 2, False], 0.9472959756851196),\n",
       " ([3, 1, 15, 3, False], 0.952946400642395),\n",
       " ([3, 1, 20, 0, False], 0.9443209409713745),\n",
       " ([3, 1, 20, 1, False], 0.9386862754821778),\n",
       " ([3, 1, 20, 2, False], 0.9279850006103516),\n",
       " ([3, 1, 20, 3, False], 0.919694471359253),\n",
       " ([3, 2, 5, 0, False], 0.9518784761428833),\n",
       " ([3, 2, 5, 1, False], 0.9641790151596069),\n",
       " ([3, 2, 5, 2, False], 0.9243540525436401),\n",
       " ([3, 2, 5, 3, False], 0.9491122007369995),\n",
       " ([3, 2, 10, 0, False], 0.9198273181915283),\n",
       " ([3, 2, 10, 1, False], 0.9152557849884033),\n",
       " ([3, 2, 10, 2, False], 0.9477567434310913),\n",
       " ([3, 2, 10, 3, False], 0.9474961996078491),\n",
       " ([3, 2, 15, 0, False], 0.9420817136764527),\n",
       " ([3, 2, 15, 1, False], 0.9439047813415528),\n",
       " ([3, 2, 15, 2, False], 0.9367182493209839),\n",
       " ([3, 2, 15, 3, False], 0.9506773710250854),\n",
       " ([3, 2, 20, 0, False], 0.9371153354644776),\n",
       " ([3, 2, 20, 1, False], 0.9503571510314941),\n",
       " ([3, 2, 20, 2, False], 0.9100825309753418),\n",
       " ([3, 2, 20, 3, False], 0.9318792819976807),\n",
       " ([3, 3, 5, 0, False], 0.9481727123260498),\n",
       " ([3, 3, 5, 1, False], 0.9221937179565429),\n",
       " ([3, 3, 5, 2, False], 0.9371119022369385),\n",
       " ([3, 3, 5, 3, False], 0.9356687068939209),\n",
       " ([3, 3, 10, 0, False], 0.9343807458877563),\n",
       " ([3, 3, 10, 1, False], 0.9835195541381836),\n",
       " ([3, 3, 10, 2, False], 0.9061741828918457),\n",
       " ([3, 3, 10, 3, False], 0.922675609588623),\n",
       " ([3, 3, 15, 0, False], 0.9511140584945679),\n",
       " ([3, 3, 15, 1, False], 0.9225685596466064),\n",
       " ([3, 3, 15, 2, False], 0.9655336141586304),\n",
       " ([3, 3, 15, 3, False], 0.9237447500228881),\n",
       " ([3, 3, 20, 0, False], 0.9236311912536621),\n",
       " ([3, 3, 20, 1, False], 0.9846024513244629),\n",
       " ([3, 3, 20, 2, False], 0.9379149198532104),\n",
       " ([3, 3, 20, 3, False], 0.9110268354415894)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(confs,list(time_r2.mean(axis=1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
