{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ced12910",
   "metadata": {},
   "source": [
    "## CAKE experiment on HB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7f9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from dataset import Dataset\n",
    "from myModel import MyModel, MyDataset\n",
    "from myExplainers import MyExplainer\n",
    "from myEvaluation import MyEvaluation\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import csv\n",
    "import warnings\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from scipy.special import softmax\n",
    "from helper import print_results\n",
    "from cake import CAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeee6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e63cf061",
   "metadata": {},
   "source": [
    "Load model, data and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4343ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''\n",
    "model_path = 'Trained Models/'\n",
    "save_path = '/home/myloniko/ethos/Results/HB/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776038e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert'\n",
    "existing_rationales = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13a5b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMultilabelSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = 'multi_label'\n",
    "labels = 6\n",
    "model = MyModel(model_path, 'bert_hummingbird', model_name, task, labels, False)\n",
    "max_sequence_len = model.tokenizer.max_len_single_sentence\n",
    "tokenizer = model.tokenizer\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "model.trainer.model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed50f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/myloniko/ethos/dataset.py:106: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  z = np.array(z)\n"
     ]
    }
   ],
   "source": [
    "hb = Dataset(path = data_path)\n",
    "x, y, label_names, rationales = hb.load_hummingbird()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1889316c",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc947105",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(y))\n",
    "train_texts, test_texts, train_labels, test_labels, _, test_indexes = train_test_split(x, y,  indices, test_size=.2, random_state=42)\n",
    "if existing_rationales:\n",
    "    test_rationales = [rationales[x] for x in test_indexes]\n",
    "\n",
    "size = (0.1 * len(y)) / len(train_labels)\n",
    "train_texts, validation_texts, train_labels, validation_labels = train_test_split(list(train_texts), train_labels, test_size=size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c27f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rationale = []\n",
    "for i in range(100):\n",
    "    rationale = []\n",
    "    test_t = test_texts[i].split(' ')\n",
    "    for j in range(6):\n",
    "        label_rational = []\n",
    "        for k in range(len(test_t)):\n",
    "            for r in tokenizer.tokenize(test_t[k]):\n",
    "                rationall = 1 if test_rationales[i][j][k] > 0 else 0\n",
    "                label_rational.append(rationall)\n",
    "        rationale.append(label_rational)\n",
    "    new_rationale.append(rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903fedf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for test_text in test_texts:\n",
    "    outputs = model.my_predict(test_text)\n",
    "    predictions.append(outputs[0])\n",
    "\n",
    "a = tf.constant(predictions, dtype = tf.float32)\n",
    "b = tf.keras.activations.sigmoid(a)\n",
    "predictions = b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3929213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4871469706211206 0.6110325760338523\n"
     ]
    }
   ],
   "source": [
    "pred_labels = []\n",
    "for prediction in predictions:\n",
    "    pred_labels.append([1 if i >= 0.5 else 0 for i in prediction])\n",
    "\n",
    "def average_precision_wrapper(y, y_pred, view):\n",
    "    return average_precision_score(y, y_pred.toarray(), average=view)\n",
    "\n",
    "print(average_precision_score(test_labels, pred_labels, average='macro'), f1_score(test_labels, pred_labels, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b66627ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'disgust', 'fear', 'joy', 'offensive', 'sadness']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "762212ee",
   "metadata": {},
   "source": [
    "Define the label descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24321d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = [\"Anger label: is a complex emotion that can manifest in a range of ways in text, such as through the use of strong, forceful language or aggressive and confrontational statements.\",\n",
    "               \"Disgust label: is typically associated with aversion or revulsion towards something that is perceived as unpleasant or offensive, such as offensive language or imagery. In text, disgust can be conveyed through a variety of linguistic cues, such as the use of negative adjectives, references to bodily fluids or waste, or explicit expressions of revulsion.\",\n",
    "               \"Fear label: is a complex emotion that is typically associated with a perceived threat or danger. In text, fear can be conveyed through a variety of linguistic cues, such as the use of negative adjectives, references to danger or risk, or explicit expressions of fear or anxiety. \",\n",
    "               \"Joy label: is typically associated with positive experiences, such as happiness, amusement, or pleasure. In text, joy can be conveyed through a variety of linguistic cues, such as the use of positive adjectives, references to pleasant experiences, or explicit expressions of happiness or enjoyment. \",\n",
    "               \"Offensive label: concerns language that can be conveyed through a variety of linguistic cues, such as the use of derogatory terms, references to marginalized groups, or explicit expressions of hate or animosity. \",\n",
    "               \"Sadness label: is typically associated with negative experiences, such as loss, grief, or disappointment. In text, sadness can be conveyed through a variety of linguistic cues, such as the use of negative adjectives, references to loss or grief, or explicit expressions of sadness or despair.\"\n",
    "]\n",
    "len(description)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c1060e2",
   "metadata": {},
   "source": [
    "Create a small cake (CAKE's instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bbc2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "cake = CAKE(model_path = 'Trained Models/bert_hummingbird', tokenizer = tokenizer, label_names = label_names, \n",
    "            label_descriptions = description, input_docs = train_texts, input_labels = list(train_labels), \n",
    "            input_docs_test = list(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60b55e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_explainers = MyExplainer(label_names, model, cake=cake)\n",
    "\n",
    "my_evaluators = MyEvaluation(label_names, model.my_predict, False, True)\n",
    "my_evaluatorsP = MyEvaluation(label_names, model.my_predict, False, False)\n",
    "evaluation =  {'F':my_evaluators.faithfulness, 'FTP': my_evaluators.faithful_truthfulness_penalty, \n",
    "          'NZW': my_evaluators.nzw, 'AUPRC': my_evaluators.auprc}\n",
    "evaluationP = {'F':my_evaluatorsP.faithfulness, 'FTP': my_evaluatorsP.faithful_truthfulness_penalty, \n",
    "          'NZW': my_evaluatorsP.nzw, 'AUPRC': my_evaluators.auprc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "918feb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs = []\n",
    "for key_emb in [1, 2, 3]:\n",
    "    for label_emb in [1, 2, \"2_doc\", 3]:\n",
    "        for keyphrases in [5, 10, 15, 20]:\n",
    "            for width in [0, 1, 2, 3, 5]:\n",
    "                for negatives in [False]:\n",
    "                    confs.append([key_emb, label_emb, keyphrases, width, negatives])\n",
    "len(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda41c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    file_name = save_path + 'HB_BERT_CAKEZ_NEW_20'+str(now.day) + '_' + str(now.month) + '_' + str(now.year)\n",
    "    metrics = {'F':[], 'FTP':[], 'AUPRC': [], 'NZW':[]}\n",
    "    metricsP = {'F':[], 'FTP':[], 'AUPRC': [], 'NZW':[]}\n",
    "    time_r = []\n",
    "    for conf in confs:\n",
    "        time_r.append([])\n",
    "    techniques = [my_explainers.cake_explain] \n",
    "    for ind in tqdm(range(0,len(test_texts))):\n",
    "        torch.cuda.empty_cache() \n",
    "        test_rational = new_rationale[ind]\n",
    "        instance = test_texts[ind]\n",
    "        my_evaluators.clear_states()\n",
    "        my_evaluatorsP.clear_states()\n",
    "        prediction, _, _ = model.my_predict(instance)\n",
    "        enc = model.tokenizer([instance,instance], truncation=True, padding=True)[0]\n",
    "        mask = enc.attention_mask\n",
    "        tokens = enc.tokens\n",
    "    \n",
    "        interpretations = []\n",
    "        kk = 0\n",
    "        for conf in confs:\n",
    "            ts = time.time()\n",
    "            if conf[1] == 3:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], ind, conf[2], conf[3], conf[4]]\n",
    "            else:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], None, conf[2], conf[3], conf[4]]\n",
    "            temp = techniques[0](instance, prediction, tokens, mask, _, _)\n",
    "            interpretations.append([np.array(i)/np.max(np.abs(i)) if np.max(np.abs(i))!=0 else np.zeros(len(i)) for i in temp])\n",
    "            time_r[kk].append(time.time()-ts)\n",
    "            kk = kk + 1\n",
    "        for metric in metrics.keys():\n",
    "            evaluated = []\n",
    "            for interpretation in interpretations:\n",
    "                evaluated.append(evaluation[metric](interpretation, _, instance, prediction, tokens, _, _, test_rational))\n",
    "            metrics[metric].append(evaluated)\n",
    "        my_evaluatorsP.saved_state = my_evaluators.saved_state.copy()\n",
    "        my_evaluators.clear_states()\n",
    "        for metric in metrics.keys():\n",
    "            evaluatedP = []\n",
    "            for interpretation in interpretations:\n",
    "                evaluatedP.append(evaluationP[metric](interpretation, _, instance, prediction, tokens, _, _, test_rational))\n",
    "            metricsP[metric].append(evaluatedP)\n",
    "        with open(file_name+'(A).pickle', 'wb') as handle:\n",
    "            pickle.dump(metrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(file_name+'(P).pickle', 'wb') as handle:\n",
    "            pickle.dump(metricsP, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(file_name+'_TIME.pickle', 'wb') as handle:\n",
    "            pickle.dump(time_r, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "time_r = np.array(time_r)\n",
    "time_r.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a7b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(file_name+'(P)', confs, metricsP, label_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "684f1a2f",
   "metadata": {},
   "source": [
    "# Time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb66c3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs = []\n",
    "for key_emb in [1, 2, 3]:\n",
    "    for label_emb in [1, 2, 3]:\n",
    "        for keyphrases in [5, 10, 15, 20]:\n",
    "            for width in [0, 1, 2, 3]:\n",
    "                for negatives in [False]:\n",
    "                    confs.append([key_emb, label_emb, keyphrases, width, negatives])\n",
    "len(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341fa9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    time_r = []\n",
    "    for conf in confs:\n",
    "        time_r.append([])\n",
    "    techniques = [my_explainers.cake_explain] \n",
    "    for ind in tqdm(range(0,10)):\n",
    "        torch.cuda.empty_cache() \n",
    "        test_rational = new_rationale[ind]\n",
    "        instance = test_texts[ind]\n",
    "        my_evaluators.clear_states()\n",
    "        my_evaluatorsP.clear_states()\n",
    "        prediction, _, _ = model.my_predict(instance)\n",
    "        enc = model.tokenizer([instance,instance], truncation=True, padding=True)[0]\n",
    "        mask = enc.attention_mask\n",
    "        tokens = enc.tokens\n",
    "    \n",
    "        interpretations = []\n",
    "        kk = 0\n",
    "        for conf in tqdm(confs):\n",
    "            ts = time.time()\n",
    "            if conf[1] == 3:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], ind, conf[2], conf[3], conf[4]]\n",
    "            else:\n",
    "                my_explainers.cake_conf = [conf[0], conf[1], None, conf[2], conf[3], conf[4]]\n",
    "            temp = techniques[0](instance, prediction, tokens, mask, _, _)\n",
    "            aa = [np.array(i)/np.max(np.abs(i)) if np.max(np.abs(i))!=0 else np.zeros(len(i)) for i in temp]\n",
    "            time_r[kk].append(time.time()-ts)\n",
    "            kk = kk + 1\n",
    "time_r = np.array(time_r)\n",
    "time_r.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97018aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1, 1, 5, 0, False], 0.13995487689971925),\n",
       " ([1, 1, 5, 1, False], 0.12349448204040528),\n",
       " ([1, 1, 5, 2, False], 0.12362327575683593),\n",
       " ([1, 1, 5, 3, False], 0.12502355575561525),\n",
       " ([1, 1, 10, 0, False], 0.12095119953155517),\n",
       " ([1, 1, 10, 1, False], 0.12590150833129882),\n",
       " ([1, 1, 10, 2, False], 0.12279009819030762),\n",
       " ([1, 1, 10, 3, False], 0.11835381984710694),\n",
       " ([1, 1, 15, 0, False], 0.12001774311065674),\n",
       " ([1, 1, 15, 1, False], 0.1228823184967041),\n",
       " ([1, 1, 15, 2, False], 0.11905977725982667),\n",
       " ([1, 1, 15, 3, False], 0.11908559799194336),\n",
       " ([1, 1, 20, 0, False], 0.11889691352844238),\n",
       " ([1, 1, 20, 1, False], 0.1221503734588623),\n",
       " ([1, 1, 20, 2, False], 0.11828882694244384),\n",
       " ([1, 1, 20, 3, False], 0.1198040246963501),\n",
       " ([1, 2, 5, 0, False], 0.11802587509155274),\n",
       " ([1, 2, 5, 1, False], 0.11724326610565186),\n",
       " ([1, 2, 5, 2, False], 0.11751015186309814),\n",
       " ([1, 2, 5, 3, False], 0.12171969413757325),\n",
       " ([1, 2, 10, 0, False], 0.1192744493484497),\n",
       " ([1, 2, 10, 1, False], 0.11874027252197265),\n",
       " ([1, 2, 10, 2, False], 0.12437834739685058),\n",
       " ([1, 2, 10, 3, False], 0.11449565887451171),\n",
       " ([1, 2, 15, 0, False], 0.12143089771270751),\n",
       " ([1, 2, 15, 1, False], 0.11931042671203614),\n",
       " ([1, 2, 15, 2, False], 0.11965882778167725),\n",
       " ([1, 2, 15, 3, False], 0.11860675811767578),\n",
       " ([1, 2, 20, 0, False], 0.12013204097747802),\n",
       " ([1, 2, 20, 1, False], 0.12584142684936522),\n",
       " ([1, 2, 20, 2, False], 0.11886670589447021),\n",
       " ([1, 2, 20, 3, False], 0.11963162422180176),\n",
       " ([1, 3, 5, 0, False], 0.11832492351531983),\n",
       " ([1, 3, 5, 1, False], 0.1182438611984253),\n",
       " ([1, 3, 5, 2, False], 0.11650381088256836),\n",
       " ([1, 3, 5, 3, False], 0.11727261543273926),\n",
       " ([1, 3, 10, 0, False], 0.11775703430175781),\n",
       " ([1, 3, 10, 1, False], 0.11444950103759766),\n",
       " ([1, 3, 10, 2, False], 0.11889550685882569),\n",
       " ([1, 3, 10, 3, False], 0.11710679531097412),\n",
       " ([1, 3, 15, 0, False], 0.12012982368469238),\n",
       " ([1, 3, 15, 1, False], 0.12004899978637695),\n",
       " ([1, 3, 15, 2, False], 0.11838514804840088),\n",
       " ([1, 3, 15, 3, False], 0.1194462776184082),\n",
       " ([1, 3, 20, 0, False], 0.1185638427734375),\n",
       " ([1, 3, 20, 1, False], 0.1187171459197998),\n",
       " ([1, 3, 20, 2, False], 0.11733531951904297),\n",
       " ([1, 3, 20, 3, False], 0.11795027256011963),\n",
       " ([2, 1, 5, 0, False], 0.8754845857620239),\n",
       " ([2, 1, 5, 1, False], 0.8242947816848755),\n",
       " ([2, 1, 5, 2, False], 0.8864991664886475),\n",
       " ([2, 1, 5, 3, False], 0.8668896675109863),\n",
       " ([2, 1, 10, 0, False], 0.8418715715408325),\n",
       " ([2, 1, 10, 1, False], 0.8741729497909546),\n",
       " ([2, 1, 10, 2, False], 0.8790560960769653),\n",
       " ([2, 1, 10, 3, False], 0.8445004224777222),\n",
       " ([2, 1, 15, 0, False], 0.8454905033111573),\n",
       " ([2, 1, 15, 1, False], 0.8832789659500122),\n",
       " ([2, 1, 15, 2, False], 0.8918931484222412),\n",
       " ([2, 1, 15, 3, False], 0.8575222253799438),\n",
       " ([2, 1, 20, 0, False], 0.8783938407897949),\n",
       " ([2, 1, 20, 1, False], 0.8841009855270385),\n",
       " ([2, 1, 20, 2, False], 0.8594229936599731),\n",
       " ([2, 1, 20, 3, False], 0.8542373657226563),\n",
       " ([2, 2, 5, 0, False], 0.8525437355041504),\n",
       " ([2, 2, 5, 1, False], 0.8808566808700562),\n",
       " ([2, 2, 5, 2, False], 0.8671150207519531),\n",
       " ([2, 2, 5, 3, False], 0.9014123916625977),\n",
       " ([2, 2, 10, 0, False], 0.8781387805938721),\n",
       " ([2, 2, 10, 1, False], 0.9208417654037475),\n",
       " ([2, 2, 10, 2, False], 0.9023085117340088),\n",
       " ([2, 2, 10, 3, False], 0.8612930059432984),\n",
       " ([2, 2, 15, 0, False], 0.8797041654586792),\n",
       " ([2, 2, 15, 1, False], 0.8904914855957031),\n",
       " ([2, 2, 15, 2, False], 0.8947327613830567),\n",
       " ([2, 2, 15, 3, False], 0.8702904224395752),\n",
       " ([2, 2, 20, 0, False], 0.9322074890136719),\n",
       " ([2, 2, 20, 1, False], 0.8537568330764771),\n",
       " ([2, 2, 20, 2, False], 0.8568142652511597),\n",
       " ([2, 2, 20, 3, False], 0.8391952753067017),\n",
       " ([2, 3, 5, 0, False], 0.8830663204193115),\n",
       " ([2, 3, 5, 1, False], 0.8647021770477294),\n",
       " ([2, 3, 5, 2, False], 0.8427675008773804),\n",
       " ([2, 3, 5, 3, False], 0.8739637613296509),\n",
       " ([2, 3, 10, 0, False], 0.8776803970336914),\n",
       " ([2, 3, 10, 1, False], 0.8618959903717041),\n",
       " ([2, 3, 10, 2, False], 0.8624455213546753),\n",
       " ([2, 3, 10, 3, False], 0.8658483266830445),\n",
       " ([2, 3, 15, 0, False], 0.8853204488754273),\n",
       " ([2, 3, 15, 1, False], 0.8623729228973389),\n",
       " ([2, 3, 15, 2, False], 0.8625772953033447),\n",
       " ([2, 3, 15, 3, False], 0.8613925457000733),\n",
       " ([2, 3, 20, 0, False], 0.8722846508026123),\n",
       " ([2, 3, 20, 1, False], 0.8401955366134644),\n",
       " ([2, 3, 20, 2, False], 0.86579909324646),\n",
       " ([2, 3, 20, 3, False], 0.9032188892364502),\n",
       " ([3, 1, 5, 0, False], 0.18626091480255128),\n",
       " ([3, 1, 5, 1, False], 0.1772411823272705),\n",
       " ([3, 1, 5, 2, False], 0.17480804920196533),\n",
       " ([3, 1, 5, 3, False], 0.17352643013000488),\n",
       " ([3, 1, 10, 0, False], 0.16958160400390626),\n",
       " ([3, 1, 10, 1, False], 0.16719064712524415),\n",
       " ([3, 1, 10, 2, False], 0.172566556930542),\n",
       " ([3, 1, 10, 3, False], 0.17301638126373292),\n",
       " ([3, 1, 15, 0, False], 0.1796522855758667),\n",
       " ([3, 1, 15, 1, False], 0.1739706039428711),\n",
       " ([3, 1, 15, 2, False], 0.17466871738433837),\n",
       " ([3, 1, 15, 3, False], 0.17478547096252442),\n",
       " ([3, 1, 20, 0, False], 0.17032761573791505),\n",
       " ([3, 1, 20, 1, False], 0.17162322998046875),\n",
       " ([3, 1, 20, 2, False], 0.16989831924438475),\n",
       " ([3, 1, 20, 3, False], 0.1671605587005615),\n",
       " ([3, 2, 5, 0, False], 0.1733323335647583),\n",
       " ([3, 2, 5, 1, False], 0.17469146251678466),\n",
       " ([3, 2, 5, 2, False], 0.17498254776000977),\n",
       " ([3, 2, 5, 3, False], 0.17244265079498292),\n",
       " ([3, 2, 10, 0, False], 0.16771960258483887),\n",
       " ([3, 2, 10, 1, False], 0.17383179664611817),\n",
       " ([3, 2, 10, 2, False], 0.17801892757415771),\n",
       " ([3, 2, 10, 3, False], 0.17422478199005126),\n",
       " ([3, 2, 15, 0, False], 0.16591124534606932),\n",
       " ([3, 2, 15, 1, False], 0.17336020469665528),\n",
       " ([3, 2, 15, 2, False], 0.17080333232879638),\n",
       " ([3, 2, 15, 3, False], 0.18557662963867189),\n",
       " ([3, 2, 20, 0, False], 0.1744304895401001),\n",
       " ([3, 2, 20, 1, False], 0.1781560182571411),\n",
       " ([3, 2, 20, 2, False], 0.1737269401550293),\n",
       " ([3, 2, 20, 3, False], 0.17820432186126708),\n",
       " ([3, 3, 5, 0, False], 0.1757650852203369),\n",
       " ([3, 3, 5, 1, False], 0.1739206314086914),\n",
       " ([3, 3, 5, 2, False], 0.16891036033630372),\n",
       " ([3, 3, 5, 3, False], 0.16983492374420167),\n",
       " ([3, 3, 10, 0, False], 0.17102231979370117),\n",
       " ([3, 3, 10, 1, False], 0.17371795177459717),\n",
       " ([3, 3, 10, 2, False], 0.17152750492095947),\n",
       " ([3, 3, 10, 3, False], 0.17453665733337403),\n",
       " ([3, 3, 15, 0, False], 0.1755384922027588),\n",
       " ([3, 3, 15, 1, False], 0.17271730899810792),\n",
       " ([3, 3, 15, 2, False], 0.17606792449951172),\n",
       " ([3, 3, 15, 3, False], 0.16949048042297363),\n",
       " ([3, 3, 20, 0, False], 0.16822426319122313),\n",
       " ([3, 3, 20, 1, False], 0.17676811218261718),\n",
       " ([3, 3, 20, 2, False], 0.16872692108154297),\n",
       " ([3, 3, 20, 3, False], 0.1728355646133423)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(confs,list(time_r.mean(axis=1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
